{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib2\n",
    "import re\n",
    "import lxml.html\n",
    "from __future__ import division\n",
    "from datetime import datetime\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "import nltk, re, pprint\n",
    "from nltk import word_tokenize\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url, user_agent='liter', num_retries=2):\n",
    "    #print('Downloading', url)\n",
    "    headers = {'User-agent': user_agent}\n",
    "    request = urllib2.Request(url, headers=headers)\n",
    "    try:\n",
    "        html = urllib2.urlopen(request).read()\n",
    "    except urllib2.URLError as e:\n",
    "        print 'Download error:', e.reason\n",
    "        html = None\n",
    "        if num_retries > 0:\n",
    "            if hasattr(e, 'code') and 500 <= e.code < 600:\n",
    "                #recursively retry 5xx HTTP errors\n",
    "                return download(url, user_agent, num_retries-1)   \n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def genre_urls(genre_url):\n",
    "    #deprecate for db-driven get_urls_dic below\n",
    "    #genre = 'fetish-stories'\n",
    "    #html = download(genre_url)\n",
    "    #tree = lxml.html.fromstring(html)\n",
    "    #story_urls = tree.xpath('//div[@class=\"b-sl-item-r w-34t\"]/h3/a/@href')\n",
    "    #story_titles = tree.xpath('//div[@class=\"b-sl-item-r w-34t\"]/h3/a/text()')\n",
    "    #story_descs = [re.sub(u'\\xa0\\u2014\\xa0','',desc) for desc in tree.xpath('//div[@class=\"b-sl-item-r w-34t\"]/span[@class=\"b-sli-description p-57u\"]/text()')]\n",
    "    #story_author_names = tree.xpath('//div[@class=\"b-sl-item-r w-34t\"]/span[@class=\"b-sli-meta\"]/span[@class=\"b-sli-author\"]/a/text()')\n",
    "    #story_author_ids = [re.match('.*uid=(\\w+)&',id).group(1) for id in tree.xpath('//div[@class=\"b-sl-item-r w-34t\"]/span[@class=\"b-sli-meta\"]/span[@class=\"b-sli-author\"]/a/@href')]\n",
    "    #story_dates = [datetime.strptime(date, '%m/%d/%y') for date in tree.xpath('//div[@class=\"b-sl-item-r w-34t\"]/span[@class=\"b-sli-meta\"]/span[@class=\"b-sli-date\"]/text()')]\n",
    "    #story_ratings = [float(rating) for rating in tree.xpath('//div[@class=\"b-sl-item-r w-34t\"]/span[@class=\"b-sli-meta\"]/span[@class=\"b-sli-rating\"]/text()')]\n",
    "    #return story_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genre_urls_dic(genre_url):\n",
    "    # given a genre, and a seed url, output a dictionary of all stats/stories/urls for a given genre\n",
    "    genre = re.findall('^.+/c/(.+)',genre_url)\n",
    "    url = genre_url+'/1-page'\n",
    "    html = download(url)\n",
    "    tree = lxml.html.fromstring(html)\n",
    "    pages = int(tree.xpath('//div[@class=\"b-pager-pages\"]/form/select/option/text()')[-1])\n",
    "    \n",
    "    genre_data = []\n",
    "    \n",
    "    for i in range(1,pages+1):\n",
    "        page_url = 'https://www.literotica.com/c/fetish-stories/%s-page' % (i)\n",
    "        # harvest data\n",
    "        ## get list of story elements\n",
    "        story_roots = tree.xpath('//div[@class=\"b-sl-item-r w-34t\"]')\n",
    "        ## loop through stories to create dic of associated data\n",
    "        for root in story_roots:\n",
    "            story_data = {}\n",
    "            story_data['genre'] = genre\n",
    "            story_data['url'] = root.xpath('./h3/a/@href')[0]\n",
    "            story_data['story_id'] = re.findall('^.+/s/(.+)|$', story_data['url'])[0]\n",
    "            story_data['title'] = root.xpath('./h3/a/text()')[0]\n",
    "            story_data['desc'] = re.sub(u'\\xa0\\u2014\\xa0','',root.xpath('./span[@class=\"b-sli-description p-57u\"]/text()')[0])\n",
    "            story_data['author_name'] = root.xpath('./span[@class=\"b-sli-meta\"]/span[@class=\"b-sli-author\"]/a/text()')[0]\n",
    "            story_data['author_id'] = re.findall('.*uid=(\\w+)&|$',root.xpath('./span[@class=\"b-sli-meta\"]/span[@class=\"b-sli-author\"]/a/@href')[0])[0]\n",
    "            story_data['created_date'] = datetime.strptime(root.xpath('./span[@class=\"b-sli-meta\"]/span[@class=\"b-sli-date\"]/text()')[0], '%m/%d/%y')\n",
    "            try:\n",
    "                story_data['rating'] = float(root.xpath('./span[@class=\"b-sli-meta\"]/span[@class=\"b-sli-rating\"]/text()')[0])\n",
    "            except (IndexError, ValueError):\n",
    "                story_data['rating'] = None\n",
    "            \n",
    "            genre_data.append(story_data)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "    return genre_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1,200 pound orgy'] \n"
     ]
    }
   ],
   "source": [
    "fetish_url = 'https://www.literotica.com/c/fetish-stories'\n",
    "html = download(fetish_url+'/1-page')\n",
    "tree = lxml.html.fromstring(html)\n",
    "story_urls = tree.xpath('//div[@class=\"b-sl-item-r w-34t\"]/h3/a/@href')\n",
    "len(story_urls)\n",
    "#story_titles = tree.xpath('//div[@class=\"b-sl-item-r w-34t\"[contains(\"%s\")]]/h3/a/text()' % (story_urls[1]))\n",
    "root = tree.xpath('//div[@class=\"b-sl-item-r w-34t\"]')\n",
    "title = root[8].xpath('./h3/a/text()')\n",
    "try:\n",
    "    rating = float(root[8].xpath('./span[@class=\"b-sli-meta\"]/span[@class=\"b-sli-rating\"]/text()'))\n",
    "except:\n",
    "    rating = ''\n",
    "print title, rating\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest = genre_urls_dic('https://www.literotica.com/c/fetish-stories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +=: 'float' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-e82e3d998030>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msummy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxtest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0msummy\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mstory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rating'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +=: 'float' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "xtest[:15]\n",
    "summy = 0\n",
    "for story in xtest:\n",
    "    summy += story['rating']\n",
    "print(summy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_story(story_url):\n",
    "    html = download(story_url)\n",
    "    tree = lxml.html.fromstring(html)\n",
    "    pages = int(re.match('(\\d+)',tree.xpath('//div[@class=\"b-pager-pages\"]/span[@class=\"b-pager-caption-t r-d45\"]/text()')[0]).group(0))\n",
    "    text = tree.xpath('//div[@class=\"b-story-body-x x-r15\"]/div/p/text()')\n",
    "    \n",
    "    story_text = []\n",
    "    story_text += text    \n",
    "    \n",
    "    if pages > 1:\n",
    "        for i in range(1,pages):\n",
    "            page_url = story_url + '?page=%s' % (i+1)\n",
    "            page_html = download(page_url)\n",
    "            page_tree = lxml.html.fromstring(page_html)\n",
    "            page_text = page_tree.xpath('//div[@class=\"b-story-body-x x-r15\"]/div/p/text()')\n",
    "            story_text += page_text\n",
    "\n",
    "    return story_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_story(raw_story):\n",
    "    tokens = word_tokenize(\" \".join(raw_story))\n",
    "    tagged = nltk.tag.pos_tag(tokens)\n",
    "    non_nnp = [word.lower() for word,tag in tagged if tag != 'NNP' and tag != 'NNPS']\n",
    "\n",
    "    content = [word for word in non_nnp if word not in stopwords and word not in punc]\n",
    "    lemmad = [lemma.lemmatize(word) for word in content]\n",
    "    \n",
    "    return lemmad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetish_url = 'https://www.literotica.com/c/fetish-stories/1-page'\n",
    "stories = []\n",
    "for i in range(1,78):\n",
    "    test_url = 'https://www.literotica.com/c/fetish-stories/%s-page' % (i)\n",
    "    stories.extend(genre_urls(test_url))\n",
    "\n",
    "len(stories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Downloading', 'https://www.literotica.com/c/fetish-stories/1-page')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = lxml.html.fromstring(download(fetish_url))\n",
    "pagex = tree.xpath('//div[@class=\"b-pager-pages\"]/form/select/option/text()')\n",
    "page_max = int(pagex[-1])\n",
    "page_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords.extend([\"n't\",\"'s\",\"''\",\"``\",\"--\",'...',\"'re\",\"'m\",'would','woman','man','dick','cock','pussy','cunt','hand','one','two','as','get','said','thought','like'])\n",
    "punc = string.punctuation\n",
    "lemma = WordNetLemmatizer()\n",
    "p_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Downloading', 'https://www.literotica.com/s/are-they-nice')\n"
     ]
    }
   ],
   "source": [
    "get_story(stories[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "prog = 0\n",
    "totes = len(stories)\n",
    "for url in stories:\n",
    "    raw_story = get_story(url)\n",
    "    texts.append(clean_story(raw_story))\n",
    "    prog += 1\n",
    "    print(str(prog) + \" of \" + str(totes) + \"(\" + str(round(prog/totes,3)*100) + \"%)\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6151326 3956 1554.93579373\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "totals = 0\n",
    "for text in texts:\n",
    "    totals += len(text)\n",
    "print totals, len(texts), totals/len(texts)\n",
    "output = open('fet-partial.pkl', 'wb')\n",
    "pickle.dump(texts, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pkl_file = open('fet-partial.pkl', 'rb')\n",
    "fet = pickle.load(pkl_file)\n",
    "pkl_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fet)\n",
    "fet1 = fet[:2000]\n",
    "fet2 = fet[2000:]\n",
    "output = open('fet-partial.pkl','wb')\n",
    "pickle.dump(fet,output)\n",
    "output.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora, models\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = 10, id2word = dictionary, passes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, u'0.012*\"would\" + 0.008*\"woman\" + 0.007*\"cock\" + 0.007*\"man\" + 0.006*\"said\" + 0.006*\"hand\" + 0.005*\"back\" + 0.005*\"thought\"')\n",
      "(1, u'0.028*\"leg\" + 0.011*\"hand\" + 0.009*\"bare\" + 0.009*\"said\" + 0.009*\"latex\" + 0.008*\"panty\" + 0.007*\"would\" + 0.006*\"could\"')\n",
      "(2, u'0.012*\"said\" + 0.011*\"could\" + 0.009*\"cock\" + 0.009*\"back\" + 0.007*\"like\" + 0.007*\"would\" + 0.006*\"time\" + 0.006*\"hand\"')\n",
      "(3, u'0.022*\"...\" + 0.009*\"would\" + 0.008*\"cock\" + 0.007*\"sow\" + 0.006*\"like\" + 0.006*\"back\" + 0.006*\"hand\" + 0.005*\"little\"')\n",
      "(4, u'0.009*\"could\" + 0.007*\"would\" + 0.006*\"one\" + 0.006*\"get\" + 0.005*\"like\" + 0.005*\"...\" + 0.005*\"time\" + 0.005*\"little\"')\n",
      "(5, u'0.002*\"hammock\" + 0.002*\"warehouse\" + 0.001*\"lycra\" + 0.001*\"squelch\" + 0.001*\"fence\" + 0.001*\"cock\" + 0.001*\"back\" + 0.001*\"taped\"')\n",
      "(6, u'0.004*\"would\" + 0.004*\"one\" + 0.003*\"like\" + 0.003*\"looked\" + 0.003*\"could\" + 0.003*\"office\" + 0.002*\"book\" + 0.002*\"mind\"')\n",
      "(7, u'0.007*\"would\" + 0.007*\"could\" + 0.006*\"like\" + 0.006*\"one\" + 0.006*\"back\" + 0.006*\"hand\" + 0.006*\"cock\" + 0.005*\"little\"')\n",
      "(8, u'0.010*\"as\" + 0.009*\"get\" + 0.008*\"hand\" + 0.008*\"cock\" + 0.007*\"back\" + 0.007*\"like\" + 0.007*\"\\'m\" + 0.006*\"one\"')\n",
      "(9, u'0.032*\"foot\" + 0.015*\"said\" + 0.010*\"face\" + 0.009*\"woman\" + 0.009*\"toe\" + 0.008*\"could\" + 0.008*\"get\" + 0.007*\"\\'re\"')\n"
     ]
    }
   ],
   "source": [
    "topics = ldamodel.print_topics(num_topics=30, num_words=8)\n",
    "for i in topics:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py2k]",
   "language": "python",
   "name": "conda-env-py2k-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
